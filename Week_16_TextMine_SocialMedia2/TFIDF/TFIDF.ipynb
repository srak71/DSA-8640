{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT ANALYTICS / MINING\n",
    "\n",
    "- Unstructured text data is being generated all the time\n",
    "\n",
    "- Text analytics / Text Mining involves techniques and algorithms for analyzing text\n",
    "\n",
    "- Traditional data mining techniques may be used if text is converted to numerical vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Techniques\n",
    "- NLTK: stemming, stopwords, punctuation, top words\n",
    "- WordCloud: visualization\n",
    "- TF-IDF Vectorizer with sklearn\n",
    "- Topic Modeling with gensim\n",
    "- Sentiment analysis with TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer with sklearn\n",
    "- Vectorizers are used to transform words into numbers\n",
    "\n",
    "- Some use a CountVectorizer â€“ just raw counts of each word in each document\n",
    "\n",
    "- But it is recommended to use TfidfVectorizer, which weights words by importance, not just by frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) CountVectorizer (i.e. Term Frequency)\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#mock data for demo purposes\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"the gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "corpus = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **fit_transform( )** method \"tokenize the strings and give you a vector for each string\". \n",
    "> \n",
    "> The vector is the total number of tokens for the whole corpus.\n",
    "> \n",
    "> Each dimension of which corresponds to the number of times a token is found in the corresponding string. \n",
    "> \n",
    "> So, it has both (1) determined which tokens it will count, and (2) how they correspond to entries in the count vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')            # create an instance object of CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(corpus) # tokenize all the strings in the corpus and return a vector for each string\n",
    "print(type(matrix))\n",
    "# csr_matrix: compressed sparse matrix\n",
    "print(matrix.shape)                       # print a stucture of the outcome (i.e. matrix variable) of fit_transform()\n",
    "                                          # (number of documents, the total number of tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **vocabulary_** method \"returns a dictionary that represents pairs of a token and its corresponding vector\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.vocabulary_)\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **get_feature_names( )** method \"returns a list that represents all the tokens (i.e. word) appearing in the corpus\". Each token is a feature of the instance object of CountVectorizer( )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's invesitgae features of the instance object.\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **toarray ( )** method \"return a dense ndarray representation of the given matrix\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each document is represented as a term-frequency vector, where each dimension corresponds to a word\n",
    "matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix.toarray())\n",
    "# But, it is not clear which feature name (i.e. token or word) is corresponding to the frequency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the feature names and the frequency! Please note that they are list objects and share the same index!\n",
    "for doc in matrix.toarray():\n",
    "    for idx in range(len(doc)):\n",
    "        print('{}:{}'.format(vectorizer.get_feature_names_out()[idx], doc[idx]), end=' ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***As we saw before, there are several words (i.e. fingers, etc.) that frequently appear in the text.***\n",
    "> ***But those words do not have the \"distinguishing\" power.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Solution: TF-IDF Vectorizer\n",
    "\n",
    "- TF: Term Frequency: how many times a word appear in a document?\n",
    "\n",
    "- IDF: Inverse Document Frequency: how many documents include the word?\n",
    "\n",
    "- TF-IDF(t, d, D) = TF(t, d) * IDF(t, D)\n",
    "\n",
    "- IDF(t, D) = log( N / |{d in D:  t in d}| )\n",
    "- N: total number of documents in the corpus\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#mock data for demo purposes\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"the gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "docs = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(stop_words='english') #Only the difference is the type of Vectorizer!\n",
    "matrix2 = vectorizer2.fit_transform(docs)\n",
    "print(vectorizer2.get_feature_names())\n",
    "print(matrix2.shape)\n",
    "print(matrix2.toarray()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare (1) CounterVectorizer and (2) TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names_out()) #(1)CounterVectorizer\n",
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer2.get_feature_names_out()) #(2)TFIDFVectorizer\n",
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix.toarray()) #(1)CounterVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix2.toarray())#(2)TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Practice:  Let's Calculate the Pairwise Document Distance with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#mock data for demo purposes\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "docs = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "matrix = vectorizer.fit_transform(docs)\n",
    "print(len(docs))\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(matrix.shape)\n",
    "print(matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **cosine_distances( )** method \"takes an object, computes cosine distance between samples in the object, and returns a distance matrix\".\n",
    ">\n",
    "> Cosine distance is defined as 1.0 minus the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "cos_dist = cosine_distances(matrix)\n",
    "print(cos_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(cos_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: The Pairwise Document Cosine-Distance with TF (i.e. CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "docs = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "matrix = vectorizer.fit_transform(docs)\n",
    "cos_dist = cosine_distances(matrix)\n",
    "print(cos_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: The Pairwise Document Cosine-Distance with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "doc1 = open('frankenstein.txt').read()\n",
    "doc2 = open('raven.txt').read()\n",
    "doc3 = open('abbey.txt').read()\n",
    "docs = [doc1, doc2, doc3]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "matrix = vectorizer.fit_transform(docs)\n",
    "cos_dist = cosine_distances(matrix)\n",
    "print(cos_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
